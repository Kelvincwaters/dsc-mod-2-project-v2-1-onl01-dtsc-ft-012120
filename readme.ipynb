{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This project entails utilizing the kc_house_data set to predict housing prices making use of a multivariate linear regression model. The initial dataset consists well over twenty-thousand rows spanding twenty-one columns at approx: 3.5MB. The price is the dependant variable and is the targeted prediction in this notebook, the features are the independent variables. The columns and descriptions in the dataset are as follows:\n",
    "* id - a notation for a house\n",
    "* date - date house was sold\n",
    "* price - price is prediction target\n",
    "* bedrooms - number of bedrooms/house\n",
    "* bathrooms - number of bathrooms/house\n",
    "* sqft_living - square footage of the home\n",
    "* sqft_loft - square footage of the lot\n",
    "* floors - total floors (levels) in the house\n",
    "* waterfront - house which has a view to a waterfront\n",
    "* view - has been viewed\n",
    "* condition - how good the condition is overall(1-5 scale, 5 being excellent)\n",
    "* grade - overall grade given to the housing unit, based on King County grading system\n",
    "* sqft_above - square footage of the house apart from the basement\n",
    "* sqft_basement - square footage of the basement\n",
    "* yr_built - year house was constructed\n",
    "\n",
    "\n",
    "#### Exploratory data analysis (EDA) questions addressed in this notebook are as follows:\n",
    "1. *What independant variables are being considered categorical and why?*\n",
    "1. *How were NaN, null, or immisable values being handled?*\n",
    "1. *Which, if any, independant variables were considered highly correlated and how was it handled?*\n",
    "1. *How were possible outliers delt with?*\n",
    "\n",
    "#### Coefficient findings and Answers:\n",
    "1. *Finding one, answer*\n",
    "1. *Finding two, answer*\n",
    "1. *Finding three, answer*\n",
    "\n",
    "> This notebook will be following the **OSEMIN** processing model and is documented accordingly\n",
    "\n",
    "<img src=\"images/new_osemn.png\" width=600>\n",
    "\n",
    "\n",
    "#### Which independent variables are being considered categorial and why? \n",
    "Views, sqft_basement, and waterfront were changed to binary values 1 or 0 as a way to view these values as \"has view, has basement, and is waterfront. It's either a yes or no. In real estate the basement is NOT calculated (much like garages here in the South) in the total sqft of the dwelling even if the basement is considered \"finished\" much like a home theatre or a dedicated kids play area, that this data doesn't indicate. \n",
    "\n",
    "```python\n",
    "# views to binary\n",
    "data.view.values[data['view'].values > 0] = 1\n",
    "# sqft_basement to binary\n",
    "data.sqft_basement.values[data['sqft_basement'].values > 0] = 1\n",
    "# waterfront to binary\n",
    "data.waterfront.values[data['waterfront'].values > 0] = 1\n",
    "-------\n",
    "data.view.value_counts()\n",
    "0.0    19422\n",
    "1.0     2112\n",
    "Name: view, dtype: int64\n",
    "1\n",
    "data.sqft_basement.value_counts()\n",
    "0.0    13280\n",
    "1.0     8317\n",
    "Name: sqft_basement, dtype: int64\n",
    "1\n",
    "data.waterfront.value_counts()\n",
    "0.0    19075\n",
    "1.0      146\n",
    "Name: waterfront, dtype: int64\n",
    "```\n",
    "#### How were NaN, null, or immiscible values being handled?\n",
    "Consequences of utilizing the dropna method wasn't feasible as it would have lead to a drop of more than 25% of the data set:\n",
    "```python\n",
    "# dropping NaN's axis= 1 col would remove to columns\n",
    "# dropping NaN's axis= 0 rows would lose more than half of the dataframe! \n",
    "drop_nans = data.dropna(axis= 0)\n",
    "display(data.shape) # original shape\n",
    "drop_nans.shape # dropna utilized shape\n",
    "(21597, 21)\n",
    "(15762, 21)\n",
    "```\n",
    "sqft_basement had values of '?' which is being assumed as unknown so those values were changed to a value of 0 \n",
    "```python\n",
    "data['sqft_basement'] = data['sqft_basement'].replace('?', '0')\n",
    "data['sqft_basement'] = data['sqft_basement'].astype(float)\n",
    "```\n",
    "#### Which, if any, independant variables were considered highly correlated and how was it handled?\n",
    "The columns sqft_living and sqft_above are duplicated values, sqft_above means the living area above grade, not excluding any basement. The sqft_above was not being considered a feature of the model. \n",
    "\n",
    "<img src=\"images/data_scrub heatmap.png\" width= 500>\n",
    "\n",
    "\n",
    "#### How were possible outliers delt with?\n",
    "A prevalent real estate metric used and missing in this data set is price_per_sqft. This was calculated and added to the data and utilized to find any underlying outliers like comparing dwelling prices by size and price. This can be searched by zipcode and comparing bedroom combinations (ie 2bdr vs 4bdr). Although it's completely feasible for tauted luxury dwelling to be marketed and priced accordingly. \n",
    "\n",
    "```python\n",
    "# comparing price between home size \n",
    "# some outliers indicate that some 2br dwellings are more expensive than 5br's in the same zipcode and sqft. \n",
    "\n",
    "def scatter(df, zipcode):\n",
    "    bed_a = data_scrub[(data.zipcode == zipcode) & (data.bedrooms == 2)] \n",
    "    bed_b = data_scrub[(data.zipcode == zipcode) & (data.bedrooms == 4)]\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = (12,7)\n",
    "    plt.scatter(bed_a.sqft_living, bed_a.price, color = 'b', label = '2br', s= 50)\n",
    "    plt.scatter(bed_b.sqft_living, bed_b.price, marker= '^', color = 'r', label = '4br', s= 50)\n",
    "\n",
    "    plt.xlabel('Sqft_living')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(zipcode)\n",
    "    plt.legend()\n",
    "\n",
    "scatter(data, 98117)\n",
    "```\n",
    "<img src=\"images/98117.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this line to run the nbconvert to readme.md github file and replace README.md"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
